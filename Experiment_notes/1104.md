# Date 1104

### Experiment 1

multi-scales , RepNet ,Video-swin-transformer pretrain model

### hyperparameter

视频长度抽取32帧，32x224x224  
scale [1]  
epoch 50  
similarity matrix heads=4 learning rate 1e-5x(1,0.8,0.64)[10,30]  
loss=loss1+loss2

### main work

encoder的输出接入全连接的网络进行了更改,从[b,f * num]->[b,f,1],从全局混合全连接变为单帧全连接. loss = loss1+loss2

### result

loss变为收敛了，实验证明不能将MAE加入loss会导致难以收敛 tensoboard scalar1104

****

### Experiment 2

### hyperparameter

视频长度抽取64帧，64x224x224  
scale [1]  
epoch 50  
similarity matrix heads=4  
learning rate 1e-5x(1,0.8,0.64)[10,30]    
loss=loss1+loss2

### main work

dataloader num_workers=20  
num_frames=64  
前5个epoch不计算backbone的梯度，显著减小显存占用。此后再全部一起学习

### result

tensorboard scalar1104_2
obo 0.2 有过拟合的能力

****

### Experiment 3

### hyperparameter

视频长度抽取64帧，64x224x224  
scale [1,4,8]  
epoch 50  
similarity matrix heads=4  
learning rate 1e-5x(1,0.8,0.64)[10,30]    
loss=loss1+loss2

### main work
多尺度融合，Replication_padding  
增加权重初始化  
特征提取部分(video-swin-transformer)全部冻结，只学习后面的部分  

### result

tensorboard scalar1104_3
训练速度减慢很多

****